{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import sleep\n",
    "sys.path.append('/My Drive/Excels útiles/')\n",
    "from functions import *\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import itertools\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy:\n",
    "\n",
    "Goal: Have most of the meli_item_id from MELI_API, taking into account that we need to prioritize most import sellers somehow.-\n",
    "\n",
    "Strategy 1:\n",
    "1. get all meli_category_ids\n",
    "2. scrape top +1.000 SKU for each meli_category_id (sorted by \"most importants\")\n",
    "3. get all meli_seller_ids related to step 2)\n",
    "4. scrape +2.000 SKUS from each meli_seller_ids related to 3) (sorted by \"most importants\", \"cheaper\" and \"expensive\"), remember to use scrape_meli_skus_largo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) get all meli_categorys_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories_df = pd.DataFrame(scrape_category_id_without_childrens('MLC'))\n",
    "#categories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories_df.to_csv(\"meli_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>total_items</th>\n",
       "      <th>ranges</th>\n",
       "      <th>percx100</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLC1196</td>\n",
       "      <td>Libros Físicos</td>\n",
       "      <td>3523063</td>\n",
       "      <td>750k&gt;x</td>\n",
       "      <td>11.815423</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLC59887</td>\n",
       "      <td>Cubre Asientos</td>\n",
       "      <td>627799</td>\n",
       "      <td>300.0k&lt;x&lt;750.0k</td>\n",
       "      <td>2.105472</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLC157694</td>\n",
       "      <td>Carcasas y Fundas</td>\n",
       "      <td>423198</td>\n",
       "      <td>300.0k&lt;x&lt;750.0k</td>\n",
       "      <td>1.419294</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLC158425</td>\n",
       "      <td>Vestidos</td>\n",
       "      <td>373022</td>\n",
       "      <td>300.0k&lt;x&lt;750.0k</td>\n",
       "      <td>1.251017</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLC22887</td>\n",
       "      <td>Pastillas de Freno</td>\n",
       "      <td>325381</td>\n",
       "      <td>300.0k&lt;x&lt;750.0k</td>\n",
       "      <td>1.091242</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7431</th>\n",
       "      <td>MLC440600</td>\n",
       "      <td>Carros Eléctricos</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;=2k</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>MLC432113</td>\n",
       "      <td>Portaflechas</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;=2k</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7433</th>\n",
       "      <td>MLC437005</td>\n",
       "      <td>Veleros</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;=2k</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7434</th>\n",
       "      <td>MLC437022</td>\n",
       "      <td>Accesorios</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;=2k</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>MLC430651</td>\n",
       "      <td>Manijas</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;=2k</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>https://api.mercadolibre.com/sites/MLC/search?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7436 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                name  total_items           ranges   percx100  \\\n",
       "0       MLC1196      Libros Físicos      3523063           750k>x  11.815423   \n",
       "1      MLC59887      Cubre Asientos       627799  300.0k<x<750.0k   2.105472   \n",
       "2     MLC157694   Carcasas y Fundas       423198  300.0k<x<750.0k   1.419294   \n",
       "3     MLC158425            Vestidos       373022  300.0k<x<750.0k   1.251017   \n",
       "4      MLC22887  Pastillas de Freno       325381  300.0k<x<750.0k   1.091242   \n",
       "...         ...                 ...          ...              ...        ...   \n",
       "7431  MLC440600   Carros Eléctricos            1             <=2k   0.000003   \n",
       "7432  MLC432113        Portaflechas            1             <=2k   0.000003   \n",
       "7433  MLC437005             Veleros            1             <=2k   0.000003   \n",
       "7434  MLC437022          Accesorios            1             <=2k   0.000003   \n",
       "7435  MLC430651             Manijas            1             <=2k   0.000003   \n",
       "\n",
       "                                                    url  \n",
       "0     https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "1     https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "2     https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "3     https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "4     https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "...                                                 ...  \n",
       "7431  https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "7432  https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "7433  https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "7434  https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "7435  https://api.mercadolibre.com/sites/MLC/search?...  \n",
       "\n",
       "[7436 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_categories = 'G:\\My Drive\\Proyectos\\[CL Scrape] Full Meli Scrape\\\\20220901\\meli_categories.csv'\n",
    "categories = pd.read_csv(\n",
    "    path_categories, usecols = ['id', 'name', 'total_items_in_this_category']).rename(\n",
    "        columns={'total_items_in_this_category':'total_items'}).sort_values(\n",
    "            by = 'total_items', ascending=False)\n",
    "categories = categories[categories['total_items'] > 0] # ~900 root_categories doesn't have any skus\n",
    "categories = categories.reset_index().drop(columns = 'index')\n",
    "categories['ranges'] =  np.where(categories.total_items <=2000, \"<=2k\",\n",
    "                        np.where(categories.total_items <=5000,  \"2.0k<x<5.0k\",\n",
    "                        np.where(categories.total_items <=10000, \"5.0k<x<10.0k\",\n",
    "                        np.where(categories.total_items <=20000, \"10.0k<x<20.0k\",\n",
    "                        np.where(categories.total_items <=50000, \"20.0k<x<50.0k\",\n",
    "                        np.where(categories.total_items <=125000, \"50.0k<x<125.0k\",\n",
    "                        np.where(categories.total_items <=300000, \"125.0k<x<300.0k\",\n",
    "                        np.where(categories.total_items <=750000, \"300.0k<x<750.0k\",\n",
    "                        \"750k>x\")\n",
    "                        )))))))\n",
    "categories['percx100'] = categories['total_items']*100/np.sum(categories['total_items'])\n",
    "categories['url'] = categories['id'].apply(lambda id: f\"https://api.mercadolibre.com/sites/MLC/search?category={id}\")\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29817494"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.total_items.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agrupada = pd.DataFrame(categories.groupby(categories.ranges).agg(\n",
    "    total_items=pd.NamedAgg(column=\"total_items\", aggfunc=\"sum\"),\n",
    "    total_categories  =pd.NamedAgg(column=\"id\", aggfunc=\"count\")\n",
    "    )\n",
    "    )\n",
    "data_agrupada['perc_items'] = np.round(data_agrupada['total_items']*100/data_agrupada['total_items'].sum(), 2)\n",
    "data_agrupada['orden'] = [4,7,2,5,8,3,6,9,1]\n",
    "data_agrupada = data_agrupada.sort_values(by = 'orden')\n",
    "data_agrupada['perc_categories'] = np.round(data_agrupada['total_categories']*100/data_agrupada['total_categories'].sum(), 2)\n",
    "data_agrupada['suma_acum_items'] = np.round(np.cumsum(data_agrupada['perc_items']),1)\n",
    "data_agrupada['suma_acum_categorías'] = np.round(np.cumsum(data_agrupada['perc_categories']),2)\n",
    "data_agrupada[['total_items', 'perc_items','suma_acum_items','total_categories', 'perc_categories', 'suma_acum_categorías', 'orden']]\n",
    "#plt.barh(x=categories['ranges'], , orientation='horizontal')\n",
    "#categories.ranges.value_counts('%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay un buen análisis de aquí, porque en realidad necesitamos saber donde hay más $$ para saber si scrapeando el 80/20 podemos hacer un buen scrapeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) scrape top +1.000 SKU for each meli_category_id\n",
    "### sorted by \"most importants\" (at least)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stragegy_2: ¿Cómo obtener todas las particiones para una categoría tal que cada partición sea de 1.000 SKUS o menos?\n",
    "\n",
    "1. Crear una función recursiva que si la partición actual tiene más de 1.000 SKUS, entonces necesita hacer una partición\n",
    "2. ¿cuantos particiones se harán? p veces, donde si p es la cantidad de particiones y s es la cantidad de skus de la partición actual\n",
    "    entonces p = int(s/1000)+1\n",
    "3. Teniendo la cantidad de particiones, se harán tantas nuevas consultas como nuevas particiones, y en cada nueva partición se hará nuevamente la pregunta ¿Tiene más de 2k de SKUS esta partición?\n",
    "4. Así sucesivamente hasta que la partición que se consulte tenga 1.000 o menos skus y esa se agrega a un listado de particiones \"válidas\".\n",
    "5. La idea es que el algoritmo también pare si es que la diferencia entre la parte altas y baja del rango es 500 pesos o menos (las particiones serán por rangos de precios: Por ejemplo, los productos de una categoría donde los precios estén entre $5.000 y $10.000), entonces no siga particionando y se agregue la actual consulta a la listado de \"válidas\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### También necesitamos crear 3 funciones\n",
    "\n",
    "1. función que entregue todas las URLs a scrapear con .get(url) que tengan 1.000 SKUS o menos, esta será la más simple\n",
    "2. función que entregue todas las URLs a scrapear con .get(url) que tengan más de 1.000 SKUS pero no más de 2.000 SKUS  (esto para buscar por &sort=price_asc' y '&sort=price_desc')\n",
    "3. función que desarolle Strategy_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_value_to_a_list_and_return_it(lista: list, new_value: any, lugar: int)-> list:\n",
    "    if lugar != len(lista):\n",
    "        lista[lugar] = new_value\n",
    "    else:\n",
    "        lista.insert(lugar, new_value)\n",
    "    return lista\n",
    "\n",
    "def crea_rangos(lista: list) -> list:\n",
    "    results = []\n",
    "    for i in range(len(lista)):\n",
    "        try:\n",
    "            new_range = str(lista[i])+'-'+str(lista[i+1])\n",
    "            results.insert(len(results), new_range)\n",
    "        except:\n",
    "            pass  \n",
    "    return results\n",
    "\n",
    "def partition_by_price(df_prices: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_prices['n_partitions'] = df_prices.apply(lambda row: 1 if (row['results'] <= 1000) else 2, axis = 1)\n",
    "    df_prices['min'] = df_prices['id'].apply(lambda row: 0 if (row[:1]  == '*') else float(row[:row.find(\"-\")-2  ])*(1 if (row[:row.find(\"-\")].find('E') == -1)   else pow(10,float(row[ row[:row.find(\"-\")].find('E')+1 : row.find(\"-\")]))))\n",
    "    df_prices['max'] = df_prices['id'].apply(lambda row: 0 if (row[-1:] == '*') else float(row[row.find(\"-\")+1:-2])*(1 if (row[row.find(\"-\")+1:].find('E') == -1) else pow(10,float(row[ row.find(\"-\")+row[row.find(\"-\"):].find('E')+1 :]))))\n",
    "    df_prices['limit_partitions'] = df_prices.apply(lambda row: list(np.linspace(start=row['min'], stop=row['max'] if (row['max'] != 0) else row['min']*1.5, num=row['n_partitions']+1 if (row['max'] != 0) else row['n_partitions'], dtype=int,  endpoint=True)) ,axis= 1)\n",
    "    df_prices['limit_partitions'] = df_prices.apply(lambda row: add_value_to_a_list_and_return_it(row['limit_partitions'], '*', 0) if (row['id'][:1] == '*') else row['limit_partitions'], axis=1)\n",
    "    df_prices['limit_partitions'] = df_prices.apply(lambda row: add_value_to_a_list_and_return_it(row['limit_partitions'], '*', len(row['limit_partitions'])) if (row['id'][-1:] == '*') else row['limit_partitions'], axis=1)\n",
    "    df_prices['add_for_close_diff'] = df_prices.apply(lambda row: np.abs(row['max'] - row['min']) <= 50, axis=1)\n",
    "    df_prices['partitions'] = df_prices['limit_partitions'].apply(lambda row: crea_rangos(row))\n",
    "    \n",
    "    return df_prices\n",
    "\n",
    "def reintentos_request(url:str) -> str:\n",
    "    segundos = 1\n",
    "    try:\n",
    "        resultado = requests.get(url)\n",
    "    except:\n",
    "        print(f\"falló un request({segundos}). {url}\")\n",
    "        sleep(segundos)\n",
    "        code = 400\n",
    "        while code != 200:\n",
    "            try:\n",
    "                resultado = requests.get(url)\n",
    "                code = resultado.status_code\n",
    "            except:\n",
    "                segundos += 1\n",
    "                sleep(segundos)\n",
    "                print(f\"falló un request({segundos}). {url}\")\n",
    "                pass\n",
    "    return resultado\n",
    "\n",
    "def scrape_meli_urls_from_category_id_2k_or_more(url_a_particionar: str)-> list:\n",
    "    urls_validas = {}\n",
    "\n",
    "    check_inicial = reintentos_request(url_a_particionar).json()\n",
    "    #print(f\"estoy haciendo la url = {url_a_particionar}. la cual tiene {check_inicial['paging']['total']} SKUS\")\n",
    "\n",
    "    if check_inicial['paging']['total'] > 1000:\n",
    "        try:\n",
    "            #dado que ambos lados del rango de precio son inclusivos, entonces se duplica un poco la información, se podría acortar el time-consuming, pero guardando en dict se solucionan los duplicados.\n",
    "            temp_prices = pd.DataFrame(pd.DataFrame(check_inicial['available_filters']).set_index('id').filter(items=['price'], axis=0)['values'][0])\n",
    "            \n",
    "        except:\n",
    "            min = float(url_a_particionar[url_a_particionar.find('&price=')+7:url_a_particionar.find('-')] if (url_a_particionar[url_a_particionar.find('&price=')+7:url_a_particionar.find('-')] != '*') else 0)\n",
    "            max = float(url_a_particionar[url_a_particionar.find('-')+1:] if (url_a_particionar[url_a_particionar.find('-')+1:] != '*') else 1.5*min)\n",
    "            middle_left = float(math.trunc((int(min) + int(max))/2))\n",
    "            middle_right = float(math.trunc((int(min) + int(max))/2))+1\n",
    "\n",
    "            temp_prices = pd.DataFrame({'id':[f\"{min}-{middle_left}\", f\"{middle_right}-{max}\" ], 'results': [\n",
    "                reintentos_request(f\"{url_a_particionar[:url_a_particionar.find('&price=')+7]}{f'{min}-{middle_left}'}\").json()['paging']['total'],\n",
    "                reintentos_request(f\"{url_a_particionar[:url_a_particionar.find('&price=')+7]}{f'{middle_right}-{max}'}\").json()['paging']['total']\n",
    "            ]})\n",
    "        #print(temp_prices)\n",
    "        temp_prices = partition_by_price(temp_prices)\n",
    "\n",
    "        temp_prices_a_agregar     = temp_prices[(temp_prices['n_partitions'] == 1) & (temp_prices['results'] > 0)  | ( temp_prices['add_for_close_diff'])]\n",
    "        temp_prices_a_particionar = temp_prices[(temp_prices['n_partitions'] > 1 ) & (temp_prices['results'] > 0)  &  (~temp_prices['add_for_close_diff'])]\n",
    "\n",
    "        urls_a_agregar_a_validas =  {}\n",
    "        for index, row in temp_prices_a_agregar.iterrows():\n",
    "            temp_url = f\"{url_a_particionar[:len(url_a_particionar) if url_a_particionar.find('&') == -1 else url_a_particionar.find('&')]}&price={row['partitions'][0]}\"\n",
    "            urls_a_agregar_a_validas[temp_url] = row['results']\n",
    "        urls_validas.update(urls_a_agregar_a_validas)\n",
    "        \n",
    "        temp_prices_a_particionar = [f\"{url_a_particionar[:len(url_a_particionar) if url_a_particionar.find('&') == -1 else url_a_particionar.find('&')]}&price={row[element]}\" for row in temp_prices_a_particionar['partitions'] for element in range(len(row))]\n",
    "\n",
    "        #print(urls_validas)\n",
    "        #print(urls_a_agregar_a_validas)\n",
    "        #print(temp_prices_a_particionar)\n",
    "\n",
    "        if len(temp_prices_a_particionar)>0:\n",
    "            for i in temp_prices_a_particionar:\n",
    "                urls_validas.update(scrape_meli_urls_from_category_id_2k_or_more(i))\n",
    "    else:\n",
    "        #print(f\"Esta tiene menos de 1.000, tiene {check_inicial['paging']['total']} así que la agregué\")\n",
    "        if check_inicial['paging']['total'] >0:\n",
    "            urls_validas[url_a_particionar] = check_inicial['paging']['total']\n",
    "    return urls_validas\n",
    "\n",
    "def scrape_meli_skus_from_dict_urls(urls_dict_url_plus_total_items: dict) -> pd.DataFrame:\n",
    "    results = pd.DataFrame({}, columns=[\n",
    "        'meli_item_id',\n",
    "        'meli_seller_id',\n",
    "        'item_name',\n",
    "        'original_price',\n",
    "        'price',\n",
    "        'condition',\n",
    "        'buying_mode',\n",
    "        'shipping',\n",
    "        'official_store_id',\n",
    "        'category_id',\n",
    "        'sold_quantity'\n",
    "    ])\n",
    "    for key, total_items in urls_dict_url_plus_total_items.items():\n",
    "        try:\n",
    "            cantidad_de_items = reintentos_request(key).json()['paging']['total']\n",
    "        except:\n",
    "            cantidad_de_items = total_items\n",
    "        multiplos = list(range(0,cantidad_de_items,50))[0:21]\n",
    "        available_sorts = ['','&sort=price_asc','&sort=price_desc']\n",
    "        #Caso en que total_items (largo de la categoría) NO es > 1050\n",
    "        if cantidad_de_items <= 1050:\n",
    "            for j in multiplos:\n",
    "                #print(f'{key}&offset={j}')\n",
    "                req = reintentos_request(url=f'{key}&offset={j}').json()\n",
    "                try:\n",
    "                    resultados = req['results']\n",
    "                    for i in resultados:\n",
    "                        \n",
    "                        try:\n",
    "                            original_price = str(int(i['original_price']))\n",
    "                        except:\n",
    "                            original_price = np.nan\n",
    "\n",
    "                        try:\n",
    "                            price = str(int(i['price']))\n",
    "                        except:\n",
    "                            price = np.nan\n",
    "                        \n",
    "                        try:\n",
    "                            official_store_id = str(int(i['official_store_id']))\n",
    "                        except:\n",
    "                            official_store_id = np.nan\n",
    "\n",
    "                        new_row  = pd.DataFrame({\n",
    "                            'meli_item_id' : i['id'],\n",
    "                            'meli_seller_id':i['seller']['id'],\n",
    "                            'item_name': i['title'],\n",
    "                            'original_price': original_price,\n",
    "                            'price': price,\n",
    "                            'condition': i['condition'],\n",
    "                            'buying_mode' : i['buying_mode'],\n",
    "                            'shipping' : str(json.dumps(i['shipping'])),\n",
    "                            'official_store_id': official_store_id,\n",
    "                            'category_id': i['category_id'],\n",
    "                            'sold_quantity': str(int(i['sold_quantity']))\n",
    "                        },\n",
    "                        columns=[\n",
    "                            'meli_item_id',\n",
    "                            'meli_seller_id',\n",
    "                            'item_name',\n",
    "                            'original_price',\n",
    "                            'price',\n",
    "                            'condition',\n",
    "                            'buying_mode',\n",
    "                            'shipping',\n",
    "                            'official_store_id',\n",
    "                            'category_id',\n",
    "                            'sold_quantity'\n",
    "                            ], index=[0])\n",
    "                        results = pd.concat([results, new_row], ignore_index=True)\n",
    "                except:\n",
    "                    #print(f'{key}&offset={j}')\n",
    "                    pass\n",
    "\n",
    "        #Caso en que la cantidad de la categoría tiene más de 1050 skus\n",
    "        else:\n",
    "            for sort_type in available_sorts:\n",
    "                for j in multiplos:\n",
    "                    req = reintentos_request(url=f'{key}&offset={j}{sort_type}').json()\n",
    "                    try:\n",
    "                        for i in req['results']:                    \n",
    "                            #print(f'{key}&offset={j}{sort_type}')    \n",
    "                            try:\n",
    "                                original_price = str(int(i['original_price']))\n",
    "                            except:\n",
    "                                original_price = np.nan\n",
    "\n",
    "                            try:\n",
    "                                price = str(int(i['price']))\n",
    "                            except:\n",
    "                                price = np.nan\n",
    "                            \n",
    "                            try:\n",
    "                                official_store_id = str(int(i['official_store_id']))\n",
    "                            except:\n",
    "                                official_store_id = np.nan\n",
    "\n",
    "                            new_row  = pd.DataFrame({\n",
    "                                'meli_item_id' : i['id'],\n",
    "                                'meli_seller_id':i['seller']['id'],\n",
    "                                'item_name': i['title'],\n",
    "                                'original_price': original_price,\n",
    "                                'price': price,\n",
    "                                'condition': i['condition'],\n",
    "                                'buying_mode' : i['buying_mode'],\n",
    "                                'shipping' : str(json.dumps(i['shipping'])),\n",
    "                                'official_store_id': official_store_id,\n",
    "                                'category_id': i['category_id'],\n",
    "                                'sold_quantity': str(int(i['sold_quantity']))\n",
    "                            },\n",
    "                            columns=[\n",
    "                                'meli_item_id',\n",
    "                                'meli_seller_id',\n",
    "                                'item_name',\n",
    "                                'original_price',\n",
    "                                'price',\n",
    "                                'condition',\n",
    "                                'buying_mode',\n",
    "                                'shipping',\n",
    "                                'official_store_id',\n",
    "                                'category_id',\n",
    "                                'sold_quantity'\n",
    "                                ], index=[0])\n",
    "                            results = pd.concat([results, new_row], ignore_index=True)\n",
    "                    except:\n",
    "                        #print(f'{key}&offset={j}')\n",
    "                        pass\n",
    "    return results.drop_duplicates()\n",
    "    \n",
    "def get_dict_withUrlPlusPriceAndTotaItems_from_listWithUrlWithoutPrice(listWithUrlWithoutPrice:list) -> dict:\n",
    "    resultsdict = {}\n",
    "    for urlWithoutPrice in listWithUrlWithoutPrice:\n",
    "        resultsdict.update(scrape_meli_urls_from_category_id_2k_or_more(urlWithoutPrice))\n",
    "    return resultsdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) get all meli_seller_ids related to step 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Time to big scrape!\n",
    "\n",
    "(scrape all urls from all root_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_url = categories['url']\n",
    "categories_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la URL es de 15K en adelante, debe hacerse por separado, el resto, en batches de 1.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareado = pd.DataFrame({}, columns=['cluster', 'id'])\n",
    "\n",
    "for i in range(len(categories)//2):\n",
    "    new_row = pd.DataFrame({\n",
    "        'cluster': i,\n",
    "        'id': [categories['id'][i], categories['id'][len(categories)-1-i]],\n",
    "    }, columns=pareado.columns\n",
    "        )\n",
    "    #print(new_row)\n",
    "    pareado = pd.concat([pareado, new_row], ignore_index=True)\n",
    "\n",
    "pareado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categories.merge(pareado, on =['id'])\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_categories_url = categories.groupby(['cluster'])['url'].apply(list).reset_index()['url']\n",
    "divided_categories_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divided_categories_url[0] #malditos libros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div0 = [\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=*-10000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=10000.0-20000.0'  ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=20000.0-30000.0'  ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=30000.0-40000.0'  ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=40000.0-50000.0'  ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=50000.0-60000.0'  ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=60000.0-70000.0'  ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=70000.0-80000.0'  ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=80000.0-90000.0'  ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=90000.0-100000.0' ],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=100000.0-125000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=125000.0-150000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=150000.0-175000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=175000.0-200000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=200000.0-225000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=225000.0-250000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=250000.0-275000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=275000.0-300000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=300000.0-325000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=325000.0-350000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=350000.0-375000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=375000.0-400000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=400000.0-500000.0'],\n",
    "    ['https://api.mercadolibre.com/sites/MLC/search?category=MLC1196&price=500000.0-*']\n",
    "    ] #libros\"\n",
    "div1 = divided_categories_url[1:800]\n",
    "div2 = divided_categories_url[800:1600]\n",
    "div3 = divided_categories_url[1600:2400]\n",
    "div4 = divided_categories_url[2400:3200]\n",
    "div5 = divided_categories_url[3200:]\n",
    "\n",
    "current = div0 # Hay que ir cambiando este valor por cada divX\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(get_dict_withUrlPlusPriceAndTotaItems_from_listWithUrlWithoutPrice, current))\n",
    "for x in results:\n",
    "    all_urls_result.update(x)\n",
    "len(all_urls_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = div1 # Hay que ir cambiando este valor por cada divX\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(get_dict_withUrlPlusPriceAndTotaItems_from_listWithUrlWithoutPrice, current))\n",
    "for x in results:\n",
    "    all_urls_result.update(x)\n",
    "len(all_urls_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = div2 # Hay que ir cambiando este valor por cada divX\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(get_dict_withUrlPlusPriceAndTotaItems_from_listWithUrlWithoutPrice, current))\n",
    "for x in results:\n",
    "    all_urls_result.update(x)\n",
    "len(all_urls_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = div3 # Hay que ir cambiando este valor por cada divX\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(get_dict_withUrlPlusPriceAndTotaItems_from_listWithUrlWithoutPrice, current))\n",
    "for x in results:\n",
    "    all_urls_result.update(x)\n",
    "len(all_urls_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = div4 # Hay que ir cambiando este valor por cada divX\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(get_dict_withUrlPlusPriceAndTotaItems_from_listWithUrlWithoutPrice, current))\n",
    "for x in results:\n",
    "    all_urls_result.update(x)\n",
    "len(all_urls_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = div5 # Hay que ir cambiando este valor por cada divX\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(get_dict_withUrlPlusPriceAndTotaItems_from_listWithUrlWithoutPrice, current))\n",
    "for x in results:\n",
    "    all_urls_result.update(x)\n",
    "len(all_urls_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_urls_result) # 1) scrape=40258 | 2) scrape=40376 | 3) scrape=43553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_urls_result, index=[\"total_items\"]).T.to_csv(\"current_all_urls_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls_result_csv = pd.read_csv(\"G:\\My Drive\\Proyectos\\[CL Scrape] Full Meli Scrape\\\\20220901\\current_all_urls_result.csv\").rename(columns={'Unnamed: 0':'url'})\n",
    "all_urls_result_csv = all_urls_result_csv[all_urls_result_csv['total_items'] > 0]\n",
    "all_urls_result = {}\n",
    "\n",
    "for index, row in all_urls_result_csv.iterrows():\n",
    "    all_urls_result[str(row['url'])] = row['total_items']\n",
    "all_urls_result;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) scrape +2.000 SKUS from each meli_seller_ids related to 3)\n",
    "### sorted by \"most importants\", \"cheaper\" and \"expensive\"\n",
    "### remember to use scrape_meli_skus_largo() also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_urls_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls_result;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "batch0 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(0   , 1000, 1)]\n",
    "\n",
    "\n",
    "current = batch0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "batch1 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(1000  , 2000, 1)]\n",
    "\n",
    "current = batch1\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch2 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(2000  , 3000, 1)]\n",
    "\n",
    "current = batch2\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch3 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(3000 ,  4000, 1)]\n",
    "\n",
    "current = batch3\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch4 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(4000 ,  5000, 1)]\n",
    "\n",
    "current = batch4\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch5 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(5000 ,  6000, 1)]\n",
    "\n",
    "\n",
    "current = batch5\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch6 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(6000 ,  7000, 1)]\n",
    "\n",
    "current = batch6\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch7 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(7000 ,  8000, 1)]\n",
    "\n",
    "\n",
    "current = batch7\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch8 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(8000 ,  9000, 1)]\n",
    "\n",
    "current = batch8\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch9 =  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(9000 , 10000, 1)]\n",
    "\n",
    "current = batch9\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch10=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(10000, 11000, 1)]\n",
    "\n",
    "current = batch10\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch11 = [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(11000, 12000, 1)]\n",
    "\n",
    "current = batch11\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch12=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(12000, 13000, 1)]\n",
    "\n",
    "current = batch12\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch13=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(13000, 14000, 1)]\n",
    "\n",
    "current = batch13\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch14=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(14000, 15000, 1)]\n",
    "\n",
    "current = batch14\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch15=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(15000, 16000, 1)]\n",
    "\n",
    "current = batch15\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch16=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(16000, 17000, 1)]\n",
    "\n",
    "current = batch16\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch16.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch17=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(17000, 18000, 1)]\n",
    "\n",
    "current = batch17\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch17.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch18=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(18000, 19000, 1)]\n",
    "\n",
    "current = batch18\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch18.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch19=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(19000, 20000, 1)]\n",
    "\n",
    "current = batch19\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC161587&price=237501-250000&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC393045&price=25000-27500&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC159295&price=35000-41250&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC159295&price=105000-152500&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC373325&price=30000-40000&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC440279&price=23750-25000&offset=250\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC439870&price=16251-16563&offset=300\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC161567&price=27500-30000&offset=200\n"
     ]
    }
   ],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "batch20=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(20000, 21000, 1)]\n",
    "\n",
    "current = batch20\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch21=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(21000, 22000, 1)]\n",
    "\n",
    "current = batch21\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch22=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(22000, 23000, 1)]\n",
    "\n",
    "current = batch22\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch23=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(23000, 24000, 1)]\n",
    "\n",
    "current = batch23\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch24=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(24000, 25000, 1)]\n",
    "\n",
    "current = batch24\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch25=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(25000, 26000, 1)]\n",
    "\n",
    "current = batch25\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch26=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(26000, 27000, 1)]\n",
    "\n",
    "\n",
    "current = batch26\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch26.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch27=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(27000, 28000, 1)]\n",
    "\n",
    "current = batch27\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch27.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch28=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(28000, 29000, 1)]\n",
    "\n",
    "current = batch28\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch28.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch29=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(29000, 30000, 1)]\n",
    "\n",
    "current = batch29\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch29.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch30=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(30000, 31000, 1)]\n",
    "\n",
    "current = batch30\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch31=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(31000, 32000, 1)]\n",
    "\n",
    "current = batch31\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch31.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch32=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(32000, 33000, 1)]\n",
    "\n",
    "current = batch32\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch33=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(33000, 34000, 1)]\n",
    "\n",
    "current = batch33\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch33.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch34=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(34000, 35000, 1)]\n",
    "\n",
    "current = batch34\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch34.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch35=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(35000, 36000, 1)]\n",
    "\n",
    "current = batch35\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch35.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch36=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(36000, 37000, 1)]\n",
    "\n",
    "current = batch36\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch36.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch37=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(37000, 38000, 1)]\n",
    "\n",
    "current = batch37\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch37.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch38=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(38000, 39000, 1)]\n",
    "\n",
    "current = batch38\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch38.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch39=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(39000, 40000, 1)]\n",
    "\n",
    "current = batch39\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch39.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC161448&offset=650\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC441039&price=95497-95503&offset=600\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC441039&price=109987-109993&offset=600\n"
     ]
    }
   ],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch40=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(40000, 41000, 1)]\n",
    "\n",
    "current = batch40\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch40.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC431656&price=9500-35000&offset=250\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC400500&price=35000-*&offset=200\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC413013&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC416202&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC174494&offset=250\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC455747&offset=200\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC417757&price=*-25000&offset=250\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC32650&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC437374&price=22500-25000&offset=100\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC417955&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC413179&offset=300\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC433785&price=*-20000&offset=100\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC434927&price=10000-15000&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC431963&offset=250\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC418776&price=15000-20000&offset=250\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC434927&price=30000-35000&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC434927&price=100000-250000&offset=150\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC418808&price=30000-*&offset=250\n",
      "falló un request(1). https://api.mercadolibre.com/sites/MLC/search?category=MLC440074&price=21251-22500&offset=250\n"
     ]
    }
   ],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch41=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(41000, 42000, 1)]\n",
    "\n",
    "current = batch41\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch41.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_full_meli_scrape = pd.DataFrame({}, columns=[\n",
    "    'meli_item_id', 'meli_seller_id', 'item_name', 'original_price', 'price', 'condition', 'buying_mode', 'shipping',\n",
    "    'official_store_id', 'category_id', 'sold_quantity'])\n",
    "\n",
    "#particiones\n",
    "\n",
    "batch42=  [dict(itertools.islice(all_urls_result.items(), i, i+1)) for i in range(42000, 43000, 1)]\n",
    "\n",
    "current = batch42\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(current)*2) as executor:\n",
    "    results = list(executor.map(scrape_meli_skus_from_dict_urls, current))\n",
    "for x in results:\n",
    "    resultados_full_meli_scrape = pd.concat([resultados_full_meli_scrape,x], ignore_index=True)\n",
    "len(resultados_full_meli_scrape)\n",
    "resultados_full_meli_scrape.to_csv(\"20220901 batch42.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "261412ca4a7cc9a72bedfc36fabb172b53a631e25a3d5d2eebc6290847b1b911"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
